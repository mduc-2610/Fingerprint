{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fingerprints for employee 101\n",
      "Successfully enrolled employee 101 with 8 fingerprints\n",
      "Processing fingerprints for employee 102\n",
      "Successfully enrolled employee 102 with 8 fingerprints\n",
      "Processing fingerprints for employee 103\n",
      "Successfully enrolled employee 103 with 8 fingerprints\n",
      "Processing fingerprints for employee 104\n",
      "Successfully enrolled employee 104 with 8 fingerprints\n",
      "Processing fingerprints for employee 105\n",
      "Successfully enrolled employee 105 with 8 fingerprints\n",
      "Processing fingerprints for employee 106\n",
      "Successfully enrolled employee 106 with 8 fingerprints\n",
      "Processing fingerprints for employee 107\n",
      "Successfully enrolled employee 107 with 8 fingerprints\n",
      "Processing fingerprints for employee 108\n",
      "Successfully enrolled employee 108 with 8 fingerprints\n",
      "Processing fingerprints for employee 109\n",
      "Successfully enrolled employee 109 with 8 fingerprints\n",
      "Processing fingerprints for employee 110\n",
      "Successfully enrolled employee 110 with 8 fingerprints\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from tensorflow.keras.metrics import Metric\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class IoU(Metric):\n",
    "    def __init__(self, name='iou', **kwargs):\n",
    "        super(IoU, self).__init__(name=name, **kwargs)\n",
    "        self.intersection = self.add_weight(name='intersection', initializer='zeros')\n",
    "        self.union = self.add_weight(name='union', initializer='zeros')\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "        intersection = tf.reduce_sum(y_true * y_pred)\n",
    "        union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "        \n",
    "        self.intersection.assign_add(intersection)\n",
    "        self.union.assign_add(union)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.intersection / (self.union + 1e-6)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.intersection.assign(0.0)\n",
    "        self.union.assign(0.0)\n",
    "\n",
    "# Load pre-trained models\n",
    "try:\n",
    "    fingerprint_recognition_model = load_model('../fingerprint_models/recognition/siamese_network.keras', custom_objects={'IoU': IoU})\n",
    "    finger_segmentation_model = load_model('../fingerprint_models/segmentation/unet_segmentation.keras', custom_objects={'IoU': IoU})\n",
    "    \n",
    "    # Get input shapes\n",
    "    if isinstance(fingerprint_recognition_model.input, list):\n",
    "        input_shape = fingerprint_recognition_model.input[0].shape[1:3]\n",
    "    else:\n",
    "        input_shape = fingerprint_recognition_model.input_shape[1:3]\n",
    "    \n",
    "    if isinstance(finger_segmentation_model.input, list):\n",
    "        segmentation_shape = finger_segmentation_model.input[0].shape[1:3]\n",
    "    else:\n",
    "        segmentation_shape = finger_segmentation_model.input_shape[1:3]\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    input_shape = (90, 90)\n",
    "    segmentation_shape = (90, 90)\n",
    "\n",
    "# Function to preprocess fingerprint images\n",
    "def preprocess_fingerprint(image_path):\n",
    "    \"\"\"Preprocess fingerprint images to match model requirements\"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image from {image_path}\")\n",
    "        \n",
    "        # Resize for segmentation\n",
    "        img_for_segmentation = cv2.resize(img, (segmentation_shape[1], segmentation_shape[0]))\n",
    "        \n",
    "        # Enhance contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        img_for_segmentation = clahe.apply(img_for_segmentation)\n",
    "        \n",
    "        # Prepare for segmentation model\n",
    "        img_for_segmentation = np.expand_dims(np.expand_dims(img_for_segmentation, axis=-1), axis=0) / 255.0\n",
    "        \n",
    "        # Get segmentation mask\n",
    "        segmentation_output = finger_segmentation_model.predict(img_for_segmentation, verbose=0)\n",
    "        \n",
    "        # Process mask\n",
    "        if isinstance(segmentation_output, list) and len(segmentation_output) > 0:\n",
    "            mask = segmentation_output[0]\n",
    "        else:\n",
    "            mask = np.ones(img.shape, dtype=np.uint8)\n",
    "        \n",
    "        mask = (mask > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Convert 3D mask to 2D if needed\n",
    "        if len(mask.shape) == 3:\n",
    "            mask_2d = mask[:, :, 0]\n",
    "        else:\n",
    "            mask_2d = mask\n",
    "        \n",
    "        # Resize mask and apply to image\n",
    "        mask_resized = cv2.resize(mask_2d, (img.shape[1], img.shape[0]))\n",
    "        img = img * mask_resized\n",
    "        \n",
    "        # Resize for recognition model\n",
    "        img = cv2.resize(img, (input_shape[1], input_shape[0]))\n",
    "        \n",
    "        # Normalize and add channel dimension\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        return img\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocess_fingerprint: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to create embedding extractor model\n",
    "def create_embedding_model(recognition_model):\n",
    "    feature_extractor = recognition_model.get_layer('functional')\n",
    "    input_shape = feature_extractor.input_shape[1:]\n",
    "    new_input = keras.layers.Input(shape=input_shape)\n",
    "    embedding = feature_extractor(new_input)\n",
    "    embedding_model = keras.Model(inputs=new_input, outputs=embedding)\n",
    "    return embedding_model\n",
    "\n",
    "# Get embedding extractor\n",
    "embedding_model = create_embedding_model(fingerprint_recognition_model)\n",
    "\n",
    "# Function to process new employee fingerprints\n",
    "def process_new_employee(employee_id, fingerprint_images_paths):\n",
    "    print(f\"Processing fingerprints for employee {employee_id}\")\n",
    "    \n",
    "    processed_dir = f\"../processed_fingerprints/employee_{employee_id}\"\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    fingerprints = []\n",
    "    \n",
    "    for i, img_path in enumerate(fingerprint_images_paths):\n",
    "        try:\n",
    "            processed_img = preprocess_fingerprint(img_path)\n",
    "            processed_path = os.path.join(processed_dir, f\"fp_{i}.npy\")\n",
    "            np.save(processed_path, processed_img)\n",
    "            fingerprints.append(processed_img)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {img_path}: {e}\")\n",
    "    \n",
    "    if len(fingerprints) == 0:\n",
    "        raise ValueError(f\"No fingerprints were successfully processed for employee {employee_id}\")\n",
    "        \n",
    "    return np.array(fingerprints)\n",
    "\n",
    "# Function to enroll employees\n",
    "def enroll_employees(employee_data_paths):\n",
    "    new_employees_data = {}\n",
    "    \n",
    "    for employee_id, image_paths in employee_data_paths.items():\n",
    "        try:\n",
    "            fingerprints = process_new_employee(employee_id, image_paths)\n",
    "            new_employees_data[employee_id] = fingerprints\n",
    "            print(f\"Successfully enrolled employee {employee_id} with {len(fingerprints)} fingerprints\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to enroll employee {employee_id}: {e}\")\n",
    "    \n",
    "    if not new_employees_data:\n",
    "        raise ValueError(\"No employees were successfully enrolled\")\n",
    "    \n",
    "    # Create embeddings database\n",
    "    embeddings_db = {}\n",
    "    for employee_id, fingerprints in new_employees_data.items():\n",
    "        employee_embeddings = embedding_model.predict(fingerprints, verbose=0)\n",
    "        embeddings_db[employee_id] = np.mean(employee_embeddings, axis=0)  # Store average embedding\n",
    "    \n",
    "    # Save embeddings database\n",
    "    os.makedirs(\"../fingerprint_adapting_models\", exist_ok=True)\n",
    "    np.save(\"../fingerprint_adapting_models/employee_embeddings.npy\", embeddings_db)\n",
    "    \n",
    "    return embeddings_db\n",
    "\n",
    "# Function to recognize employees from new fingerprint\n",
    "def recognize_employee(image_path, embeddings_db=None, threshold=0.7):\n",
    "    try:\n",
    "        # Preprocess image\n",
    "        processed_img = preprocess_fingerprint(image_path)\n",
    "        processed_img = np.expand_dims(processed_img, axis=0)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Similarity matching using embeddings\n",
    "        if embeddings_db is not None:\n",
    "            # Get embedding for the input fingerprint\n",
    "            embedding = embedding_model.predict(processed_img, verbose=0)[0]\n",
    "            \n",
    "            # Find most similar embedding\n",
    "            best_match = None\n",
    "            best_similarity = -1\n",
    "            \n",
    "            for employee_id, stored_embedding in embeddings_db.items():\n",
    "                # Compute cosine similarity\n",
    "                similarity = np.dot(embedding, stored_embedding) / (np.linalg.norm(embedding) * np.linalg.norm(stored_embedding))\n",
    "                \n",
    "                if similarity > best_similarity:\n",
    "                    best_similarity = similarity\n",
    "                    best_match = employee_id\n",
    "            \n",
    "            if best_similarity >= threshold:\n",
    "                results[\"similarity\"] = {\"employee_id\": best_match, \"confidence\": float(best_similarity)}\n",
    "            else:\n",
    "                results[\"similarity\"] = {\"employee_id\": None, \"confidence\": float(best_similarity)}\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during recognition: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def generate_employee_data(dir):\n",
    "    employee_data = {}\n",
    "    for _employee_id in os.listdir(dir):\n",
    "        employee_data[_employee_id] = []\n",
    "        for _employee_fingerprint in os.listdir(f\"{dir}/{_employee_id}\"):\n",
    "            employee_data[_employee_id].append(f\"{dir}/{_employee_id}/{_employee_fingerprint}\")\n",
    "    return employee_data\n",
    "\n",
    "# Check if models are loaded successfully\n",
    "if 'fingerprint_recognition_model' not in globals() or 'finger_segmentation_model' not in globals():\n",
    "    print(\"Models failed to load. Please check model paths and formats.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Ensure data paths are correct\n",
    "EMPLOYEE_DIR = \"../fingerprint_adapting_test_dataset\"\n",
    "employee_data_paths = generate_employee_data(dir=EMPLOYEE_DIR)\n",
    "\n",
    "try:\n",
    "    # Enroll employees\n",
    "    embeddings_db = enroll_employees(employee_data_paths)\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing recognition with image: ../fingerprint_adapting_test_dataset/109/109_4.tif\n",
      "Expected ID: 109\n",
      "Recognized ID: 109\n",
      "Confidence: 0.85\n",
      "{'similarity': {'employee_id': '109', 'confidence': 0.8517934083938599}}\n",
      "✅ MATCH SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "# Test recognition with random employee\n",
    "random_employee_id = random.randint(102, 109)\n",
    "random_employee_fingerprint_position = random.randint(1, 5)\n",
    "test_image = f\"{EMPLOYEE_DIR}/{random_employee_id}/{random_employee_id}_{random_employee_fingerprint_position}.tif\"\n",
    "if os.path.exists(test_image):\n",
    "    print(f\"Testing recognition with image: {test_image}\")\n",
    "    result = recognize_employee(\n",
    "        test_image, \n",
    "        embeddings_db=embeddings_db\n",
    "    )\n",
    "    \n",
    "    # Compare expected vs actual results\n",
    "    expected_id = str(random_employee_id)\n",
    "    actual_id = result.get('similarity', {}).get('employee_id')\n",
    "    confidence = result.get('similarity', {}).get('confidence', 0)\n",
    "    \n",
    "    print(f\"Expected ID: {expected_id}\")\n",
    "    print(f\"Recognized ID: {actual_id}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "    print(f\"{result}\")\n",
    "    if expected_id == actual_id:\n",
    "        print(\"✅ MATCH SUCCESSFUL!\")\n",
    "    else:\n",
    "        print(\"❌ MATCH FAILED!\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Test image {test_image} not found!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recognition Accuracy: 53.75% (43/80 successful matches)\n"
     ]
    }
   ],
   "source": [
    "def test_recognition_accuracy(employee_data_paths, embeddings_db, threshold=0.7):\n",
    "    total_tests = 0\n",
    "    successful_matches = 0\n",
    "\n",
    "    for employee_id, image_paths in employee_data_paths.items():\n",
    "        for img_path in image_paths:\n",
    "            if os.path.exists(img_path):\n",
    "                result = recognize_employee(img_path, embeddings_db=embeddings_db, threshold=threshold)\n",
    "                \n",
    "                expected_id = str(employee_id)\n",
    "                actual_id = result.get('similarity', {}).get('employee_id')\n",
    "                confidence = result.get('similarity', {}).get('confidence', 0)\n",
    "\n",
    "                # print(f\"\\nTesting Image: {img_path}\")\n",
    "                # print(f\"Expected ID: {expected_id}\")\n",
    "                # print(f\"Recognized ID: {actual_id}\")\n",
    "                # print(f\"Confidence: {confidence:.2f}\")\n",
    "\n",
    "                if expected_id == actual_id:\n",
    "                    # print(\"✅ MATCH SUCCESSFUL!\")\n",
    "                    successful_matches += 1\n",
    "                # else:\n",
    "                #     print(\"❌ MATCH FAILED!\")\n",
    "\n",
    "                total_tests += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    if total_tests > 0:\n",
    "        accuracy = (successful_matches / total_tests) * 100\n",
    "        print(f\"\\nRecognition Accuracy: {accuracy:.2f}% ({successful_matches}/{total_tests} successful matches)\")\n",
    "    else:\n",
    "        print(\"No test cases found!\")\n",
    "\n",
    "# Run accuracy test\n",
    "test_recognition_accuracy(employee_data_paths, embeddings_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fingerprint recognition improvement process...\n",
      "Loaded existing embeddings database with 10 employees\n",
      "\n",
      "Initial accuracy test:\n",
      "\n",
      "Recognition Accuracy: 53.75% (43/80 successful matches)\n",
      "Starting iterative training with initial accuracy: 0.00%\n",
      "Target accuracy: 90.00%\n",
      "\n",
      "--- Iteration 1/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 53.75% (43/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 7 misclassified samples\n",
      "Updated embedding for employee 102 with 3 misclassified samples\n",
      "Updated embedding for employee 103 with 8 misclassified samples\n",
      "Updated embedding for employee 104 with 4 misclassified samples\n",
      "Updated embedding for employee 105 with 1 misclassified samples\n",
      "Updated embedding for employee 106 with 3 misclassified samples\n",
      "Updated embedding for employee 107 with 3 misclassified samples\n",
      "Updated embedding for employee 108 with 4 misclassified samples\n",
      "Updated embedding for employee 109 with 2 misclassified samples\n",
      "Updated embedding for employee 110 with 2 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_1.npy\n",
      "\n",
      "--- Iteration 2/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 33.75% (27/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 7 misclassified samples\n",
      "Updated embedding for employee 102 with 2 misclassified samples\n",
      "Updated embedding for employee 103 with 4 misclassified samples\n",
      "Updated embedding for employee 104 with 6 misclassified samples\n",
      "Updated embedding for employee 105 with 7 misclassified samples\n",
      "Updated embedding for employee 106 with 5 misclassified samples\n",
      "Updated embedding for employee 107 with 6 misclassified samples\n",
      "Updated embedding for employee 108 with 3 misclassified samples\n",
      "Updated embedding for employee 109 with 7 misclassified samples\n",
      "Updated embedding for employee 110 with 6 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_2.npy\n",
      "\n",
      "--- Iteration 3/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 56.25% (45/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 4 misclassified samples\n",
      "Updated embedding for employee 102 with 5 misclassified samples\n",
      "Updated embedding for employee 103 with 5 misclassified samples\n",
      "Updated embedding for employee 104 with 3 misclassified samples\n",
      "Updated embedding for employee 105 with 1 misclassified samples\n",
      "Updated embedding for employee 106 with 4 misclassified samples\n",
      "Updated embedding for employee 107 with 3 misclassified samples\n",
      "Updated embedding for employee 108 with 4 misclassified samples\n",
      "Updated embedding for employee 109 with 3 misclassified samples\n",
      "Updated embedding for employee 110 with 3 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_3.npy\n",
      "\n",
      "--- Iteration 4/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:12<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 40.00% (32/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 5 misclassified samples\n",
      "Updated embedding for employee 102 with 1 misclassified samples\n",
      "Updated embedding for employee 103 with 4 misclassified samples\n",
      "Updated embedding for employee 104 with 6 misclassified samples\n",
      "Updated embedding for employee 105 with 7 misclassified samples\n",
      "Updated embedding for employee 106 with 4 misclassified samples\n",
      "Updated embedding for employee 107 with 7 misclassified samples\n",
      "Updated embedding for employee 108 with 3 misclassified samples\n",
      "Updated embedding for employee 109 with 6 misclassified samples\n",
      "Updated embedding for employee 110 with 5 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_4.npy\n",
      "\n",
      "--- Iteration 5/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:23<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 50.00% (40/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 4 misclassified samples\n",
      "Updated embedding for employee 102 with 7 misclassified samples\n",
      "Updated embedding for employee 103 with 6 misclassified samples\n",
      "Updated embedding for employee 104 with 4 misclassified samples\n",
      "Updated embedding for employee 105 with 2 misclassified samples\n",
      "Updated embedding for employee 106 with 5 misclassified samples\n",
      "Updated embedding for employee 107 with 3 misclassified samples\n",
      "Updated embedding for employee 108 with 4 misclassified samples\n",
      "Updated embedding for employee 109 with 3 misclassified samples\n",
      "Updated embedding for employee 110 with 2 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_5.npy\n",
      "\n",
      "--- Iteration 6/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:27<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 42.50% (34/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 5 misclassified samples\n",
      "Updated embedding for employee 103 with 7 misclassified samples\n",
      "Updated embedding for employee 104 with 7 misclassified samples\n",
      "Updated embedding for employee 105 with 6 misclassified samples\n",
      "Updated embedding for employee 106 with 2 misclassified samples\n",
      "Updated embedding for employee 107 with 5 misclassified samples\n",
      "Updated embedding for employee 108 with 3 misclassified samples\n",
      "Updated embedding for employee 109 with 5 misclassified samples\n",
      "Updated embedding for employee 110 with 6 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_6.npy\n",
      "\n",
      "--- Iteration 7/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 58.75% (47/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 5 misclassified samples\n",
      "Updated embedding for employee 102 with 3 misclassified samples\n",
      "Updated embedding for employee 103 with 5 misclassified samples\n",
      "Updated embedding for employee 104 with 3 misclassified samples\n",
      "Updated embedding for employee 105 with 1 misclassified samples\n",
      "Updated embedding for employee 106 with 5 misclassified samples\n",
      "Updated embedding for employee 107 with 3 misclassified samples\n",
      "Updated embedding for employee 108 with 3 misclassified samples\n",
      "Updated embedding for employee 109 with 3 misclassified samples\n",
      "Updated embedding for employee 110 with 2 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_7.npy\n",
      "\n",
      "--- Iteration 8/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:13<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 33.75% (27/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 7 misclassified samples\n",
      "Updated embedding for employee 102 with 2 misclassified samples\n",
      "Updated embedding for employee 103 with 6 misclassified samples\n",
      "Updated embedding for employee 104 with 6 misclassified samples\n",
      "Updated embedding for employee 105 with 7 misclassified samples\n",
      "Updated embedding for employee 106 with 4 misclassified samples\n",
      "Updated embedding for employee 107 with 6 misclassified samples\n",
      "Updated embedding for employee 108 with 3 misclassified samples\n",
      "Updated embedding for employee 109 with 6 misclassified samples\n",
      "Updated embedding for employee 110 with 6 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_8.npy\n",
      "\n",
      "--- Iteration 9/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:28<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 60.00% (48/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 4 misclassified samples\n",
      "Updated embedding for employee 102 with 3 misclassified samples\n",
      "Updated embedding for employee 103 with 6 misclassified samples\n",
      "Updated embedding for employee 104 with 4 misclassified samples\n",
      "Updated embedding for employee 105 with 1 misclassified samples\n",
      "Updated embedding for employee 106 with 3 misclassified samples\n",
      "Updated embedding for employee 107 with 2 misclassified samples\n",
      "Updated embedding for employee 108 with 4 misclassified samples\n",
      "Updated embedding for employee 109 with 3 misclassified samples\n",
      "Updated embedding for employee 110 with 2 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_9.npy\n",
      "\n",
      "--- Iteration 10/10 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing samples: 100%|██████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recognition Accuracy: 36.25% (29/80 successful matches)\n",
      "Updating embeddings with focus on misclassified samples...\n",
      "Updated embedding for employee 101 with 5 misclassified samples\n",
      "Updated embedding for employee 102 with 2 misclassified samples\n",
      "Updated embedding for employee 103 with 4 misclassified samples\n",
      "Updated embedding for employee 104 with 6 misclassified samples\n",
      "Updated embedding for employee 105 with 7 misclassified samples\n",
      "Updated embedding for employee 106 with 6 misclassified samples\n",
      "Updated embedding for employee 107 with 6 misclassified samples\n",
      "Updated embedding for employee 108 with 3 misclassified samples\n",
      "Updated embedding for employee 109 with 6 misclassified samples\n",
      "Updated embedding for employee 110 with 6 misclassified samples\n",
      "Saved updated embeddings as employee_embeddings_iter_10.npy\n",
      "\n",
      "Final Recognition Accuracy: 52.50% (42/80 successful matches)\n",
      "Saved improved embeddings database as 'employee_embeddings_improved.npy'\n",
      "\n",
      "Fingerprint recognition system improved to 52.50%, but did not reach target accuracy of 90%.\n",
      "Consider adjusting parameters or collecting more fingerprint samples for problematic employees.\n"
     ]
    }
   ],
   "source": [
    "def iterative_training_improvement(employee_data_paths, embeddings_db, target_accuracy=90.0, max_iterations=10, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Iteratively improve fingerprint recognition accuracy by focusing on misclassified samples\n",
    "    \n",
    "    Args:\n",
    "        employee_data_paths: Dictionary mapping employee IDs to their fingerprint image paths\n",
    "        embeddings_db: Initial embeddings database\n",
    "        target_accuracy: Target accuracy percentage to achieve\n",
    "        max_iterations: Maximum number of training iterations to perform\n",
    "        threshold: Similarity threshold for recognition\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (final_embeddings_db, final_accuracy)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from tqdm import tqdm\n",
    "    import copy\n",
    "    \n",
    "    current_embeddings_db = copy.deepcopy(embeddings_db)\n",
    "    iteration = 0\n",
    "    current_accuracy = 0.0\n",
    "    \n",
    "    print(f\"Starting iterative training with initial accuracy: {current_accuracy:.2f}%\")\n",
    "    print(f\"Target accuracy: {target_accuracy:.2f}%\")\n",
    "    \n",
    "    while current_accuracy < target_accuracy and iteration < max_iterations:\n",
    "        iteration += 1\n",
    "        print(f\"\\n--- Iteration {iteration}/{max_iterations} ---\")\n",
    "        \n",
    "        # Test current accuracy and collect misclassified samples\n",
    "        total_tests = 0\n",
    "        successful_matches = 0\n",
    "        misclassified_samples = {}  # employee_id -> list of misclassified fingerprints\n",
    "        \n",
    "        for employee_id, image_paths in tqdm(employee_data_paths.items(), desc=\"Testing samples\"):\n",
    "            misclassified_samples[employee_id] = []\n",
    "            \n",
    "            for img_path in image_paths:\n",
    "                if os.path.exists(img_path):\n",
    "                    result = recognize_employee(img_path, embeddings_db=current_embeddings_db, threshold=threshold)\n",
    "                    \n",
    "                    expected_id = str(employee_id)\n",
    "                    actual_id = result.get('similarity', {}).get('employee_id')\n",
    "                    \n",
    "                    if expected_id == actual_id:\n",
    "                        successful_matches += 1\n",
    "                    else:\n",
    "                        # Store misclassified samples for retraining\n",
    "                        misclassified_samples[employee_id].append(img_path)\n",
    "                    \n",
    "                    total_tests += 1\n",
    "        \n",
    "        # Calculate current accuracy\n",
    "        if total_tests > 0:\n",
    "            current_accuracy = (successful_matches / total_tests) * 100\n",
    "            print(f\"Current Recognition Accuracy: {current_accuracy:.2f}% ({successful_matches}/{total_tests} successful matches)\")\n",
    "        else:\n",
    "            print(\"No test cases found!\")\n",
    "            break\n",
    "        \n",
    "        # If we've reached target accuracy, break\n",
    "        if current_accuracy >= target_accuracy:\n",
    "            print(f\"Target accuracy of {target_accuracy:.2f}% achieved!\")\n",
    "            break\n",
    "            \n",
    "        # Otherwise, update embeddings with focus on misclassified samples\n",
    "        print(\"Updating embeddings with focus on misclassified samples...\")\n",
    "        \n",
    "        for employee_id, misclassified_paths in misclassified_samples.items():\n",
    "            if not misclassified_paths:\n",
    "                continue  # Skip if no misclassified samples for this employee\n",
    "                \n",
    "            try:\n",
    "                # Process misclassified fingerprints\n",
    "                misclassified_fingerprints = []\n",
    "                for img_path in misclassified_paths:\n",
    "                    processed_img = preprocess_fingerprint(img_path)\n",
    "                    misclassified_fingerprints.append(processed_img)\n",
    "                \n",
    "                if misclassified_fingerprints:\n",
    "                    misclassified_fingerprints = np.array(misclassified_fingerprints)\n",
    "                    \n",
    "                    # Get embeddings for misclassified fingerprints\n",
    "                    misclassified_embeddings = embedding_model.predict(misclassified_fingerprints, verbose=0)\n",
    "                    \n",
    "                    # Weight the misclassified samples more heavily in the updated embedding\n",
    "                    # If this is the first iteration, we need to convert from the saved format\n",
    "                    if isinstance(current_embeddings_db[employee_id], np.ndarray) and current_embeddings_db[employee_id].ndim == 1:\n",
    "                        current_embedding = current_embeddings_db[employee_id]\n",
    "                    else:\n",
    "                        # Handle case where embeddings_db might store more complex data\n",
    "                        current_embedding = np.mean(current_embeddings_db[employee_id], axis=0) if isinstance(current_embeddings_db[employee_id], np.ndarray) else current_embeddings_db[employee_id]\n",
    "                    \n",
    "                    # Weighted average: give more weight to misclassified samples\n",
    "                    misclassified_weight = 2.0  # Adjust this weight as needed\n",
    "                    updated_embedding = (current_embedding + misclassified_weight * np.mean(misclassified_embeddings, axis=0)) / (1.0 + misclassified_weight)\n",
    "                    \n",
    "                    # Update the embedding in the database\n",
    "                    current_embeddings_db[employee_id] = updated_embedding\n",
    "                    \n",
    "                    print(f\"Updated embedding for employee {employee_id} with {len(misclassified_fingerprints)} misclassified samples\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error updating embeddings for employee {employee_id}: {e}\")\n",
    "        \n",
    "        # Save updated embeddings database\n",
    "        os.makedirs(\"../fingerprint_adapting_models\", exist_ok=True)\n",
    "        np.save(f\"../fingerprint_adapting_models/employee_embeddings_iter_{iteration}.npy\", current_embeddings_db)\n",
    "        print(f\"Saved updated embeddings as employee_embeddings_iter_{iteration}.npy\")\n",
    "    \n",
    "    # Final accuracy test\n",
    "    total_tests = 0\n",
    "    successful_matches = 0\n",
    "    \n",
    "    for employee_id, image_paths in employee_data_paths.items():\n",
    "        for img_path in image_paths:\n",
    "            if os.path.exists(img_path):\n",
    "                result = recognize_employee(img_path, embeddings_db=current_embeddings_db, threshold=threshold)\n",
    "                \n",
    "                expected_id = str(employee_id)\n",
    "                actual_id = result.get('similarity', {}).get('employee_id') \n",
    "                \n",
    "                if expected_id == actual_id:\n",
    "                    successful_matches += 1\n",
    "                \n",
    "                total_tests += 1\n",
    "    \n",
    "    final_accuracy = (successful_matches / total_tests) * 100 if total_tests > 0 else 0.0\n",
    "    print(f\"\\nFinal Recognition Accuracy: {final_accuracy:.2f}% ({successful_matches}/{total_tests} successful matches)\")\n",
    "    \n",
    "    return current_embeddings_db, final_accuracy\n",
    "\n",
    "\n",
    "# Function to visualize accuracy improvement over iterations\n",
    "def plot_accuracy_improvement(accuracies):\n",
    "    \"\"\"\n",
    "    Plot the accuracy improvement over iterations\n",
    "    \n",
    "    Args:\n",
    "        accuracies: List of accuracy values per iteration\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, len(accuracies) + 1), accuracies, 'o-', linewidth=2, markersize=8)\n",
    "        plt.axhline(y=90, color='r', linestyle='--', label='Target (90%)')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Accuracy (%)')\n",
    "        plt.title('Fingerprint Recognition Accuracy Improvement')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Save the plot\n",
    "        plt.savefig('../fingerprint_adapting_models/accuracy_improvement.png')\n",
    "        plt.close()\n",
    "        print(\"Accuracy improvement plot saved as 'accuracy_improvement.png'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating accuracy plot: {e}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def improve_fingerprint_recognition():\n",
    "    print(\"Starting fingerprint recognition improvement process...\")\n",
    "    \n",
    "    # Load embeddings database if it exists\n",
    "    embeddings_path = \"../fingerprint_adapting_models/employee_embeddings.npy\"\n",
    "    if os.path.exists(embeddings_path):\n",
    "        try:\n",
    "            # Load the embeddings - need to handle the special dictionary format\n",
    "            loaded_data = np.load(embeddings_path, allow_pickle=True)\n",
    "            if isinstance(loaded_data, np.ndarray) and loaded_data.dtype == np.dtype('O') and loaded_data.shape == ():\n",
    "                embeddings_db = loaded_data.item()\n",
    "            else:\n",
    "                embeddings_db = loaded_data\n",
    "            print(f\"Loaded existing embeddings database with {len(embeddings_db)} employees\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading embeddings: {e}\")\n",
    "            embeddings_db = {}\n",
    "    else:\n",
    "        print(\"No existing embeddings database found. Creating new database...\")\n",
    "        embeddings_db = enroll_employees(employee_data_paths)\n",
    "    \n",
    "    # Run initial accuracy test\n",
    "    print(\"\\nInitial accuracy test:\")\n",
    "    initial_accuracy = test_recognition_accuracy(employee_data_paths, embeddings_db)\n",
    "    \n",
    "    # Run iterative improvement\n",
    "    accuracies = [initial_accuracy]\n",
    "    improved_embeddings_db, final_accuracy = iterative_training_improvement(\n",
    "        employee_data_paths=employee_data_paths,\n",
    "        embeddings_db=embeddings_db,\n",
    "        target_accuracy=90.0,\n",
    "        max_iterations=10,\n",
    "        threshold=0.7\n",
    "    )\n",
    "    \n",
    "    # Save final embeddings\n",
    "    np.save(\"../fingerprint_adapting_models/employee_embeddings_improved.npy\", improved_embeddings_db)\n",
    "    print(\"Saved improved embeddings database as 'employee_embeddings_improved.npy'\")\n",
    "    \n",
    "    return improved_embeddings_db, final_accuracy\n",
    "\n",
    "\n",
    "# Fix the test_recognition_accuracy function to return the accuracy value\n",
    "def test_recognition_accuracy(employee_data_paths, embeddings_db, threshold=0.7):\n",
    "    total_tests = 0\n",
    "    successful_matches = 0\n",
    "    \n",
    "    for employee_id, image_paths in employee_data_paths.items():\n",
    "        for img_path in image_paths:\n",
    "            if os.path.exists(img_path):\n",
    "                result = recognize_employee(img_path, embeddings_db=embeddings_db, threshold=threshold)\n",
    "                \n",
    "                expected_id = str(employee_id)\n",
    "                actual_id = result.get('similarity', {}).get('employee_id')\n",
    "                confidence = result.get('similarity', {}).get('confidence', 0)\n",
    "                \n",
    "                if expected_id == actual_id:\n",
    "                    successful_matches += 1\n",
    "                \n",
    "                total_tests += 1\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    if total_tests > 0:\n",
    "        accuracy = (successful_matches / total_tests) * 100\n",
    "        print(f\"\\nRecognition Accuracy: {accuracy:.2f}% ({successful_matches}/{total_tests} successful matches)\")\n",
    "    else:\n",
    "        print(\"No test cases found!\")\n",
    "        accuracy = 0.0\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# If run as main script\n",
    "# Run the improvement process\n",
    "improved_embeddings_db, final_accuracy = improve_fingerprint_recognition()\n",
    "\n",
    "# Use the improved embeddings for recognition\n",
    "if final_accuracy >= 90.0:\n",
    "    print(\"\\nFingerprint recognition system successfully improved to target accuracy!\")\n",
    "else:\n",
    "    print(f\"\\nFingerprint recognition system improved to {final_accuracy:.2f}%, but did not reach target accuracy of 90%.\")\n",
    "    print(\"Consider adjusting parameters or collecting more fingerprint samples for problematic employees.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
