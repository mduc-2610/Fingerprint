{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fingerprints for employee 101\n",
      "Successfully enrolled employee 101 with 5 fingerprints\n",
      "Processing fingerprints for employee 102\n",
      "Successfully enrolled employee 102 with 8 fingerprints\n",
      "Processing fingerprints for employee 103\n",
      "Successfully enrolled employee 103 with 8 fingerprints\n",
      "Processing fingerprints for employee 104\n",
      "Successfully enrolled employee 104 with 8 fingerprints\n",
      "Processing fingerprints for employee 105\n",
      "Successfully enrolled employee 105 with 8 fingerprints\n",
      "Processing fingerprints for employee 106\n",
      "Successfully enrolled employee 106 with 8 fingerprints\n",
      "Processing fingerprints for employee 107\n",
      "Successfully enrolled employee 107 with 8 fingerprints\n",
      "Processing fingerprints for employee 108\n",
      "Successfully enrolled employee 108 with 8 fingerprints\n",
      "Processing fingerprints for employee 109\n",
      "Successfully enrolled employee 109 with 8 fingerprints\n",
      "Processing fingerprints for employee 110\n",
      "Successfully enrolled employee 110 with 8 fingerprints\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import random\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from tensorflow.keras.metrics import Metric\n",
    "\n",
    "@keras.saving.register_keras_serializable()\n",
    "class IoU(Metric):\n",
    "    def __init__(self, name='iou', **kwargs):\n",
    "        super(IoU, self).__init__(name=name, **kwargs)\n",
    "        self.intersection = self.add_weight(name='intersection', initializer='zeros')\n",
    "        self.union = self.add_weight(name='union', initializer='zeros')\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.cast(y_pred > 0.5, tf.float32)\n",
    "        intersection = tf.reduce_sum(y_true * y_pred)\n",
    "        union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "        \n",
    "        self.intersection.assign_add(intersection)\n",
    "        self.union.assign_add(union)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.intersection / (self.union + 1e-6)\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.intersection.assign(0.0)\n",
    "        self.union.assign(0.0)\n",
    "\n",
    "# Load pre-trained models\n",
    "try:\n",
    "    fingerprint_recognition_model = load_model('../fingerprint_models/recognition/siamese_network.keras', custom_objects={'IoU': IoU})\n",
    "    finger_segmentation_model = load_model('../fingerprint_models/segmentation/unet_segmentation.keras', custom_objects={'IoU': IoU})\n",
    "    \n",
    "    # Get input shapes\n",
    "    if isinstance(fingerprint_recognition_model.input, list):\n",
    "        input_shape = fingerprint_recognition_model.input[0].shape[1:3]\n",
    "    else:\n",
    "        input_shape = fingerprint_recognition_model.input_shape[1:3]\n",
    "    \n",
    "    if isinstance(finger_segmentation_model.input, list):\n",
    "        segmentation_shape = finger_segmentation_model.input[0].shape[1:3]\n",
    "    else:\n",
    "        segmentation_shape = finger_segmentation_model.input_shape[1:3]\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    input_shape = (90, 90)\n",
    "    segmentation_shape = (90, 90)\n",
    "\n",
    "# Function to preprocess fingerprint images\n",
    "def preprocess_fingerprint(image_path):\n",
    "    \"\"\"Preprocess fingerprint images to match model requirements\"\"\"\n",
    "    try:\n",
    "        # Read image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load image from {image_path}\")\n",
    "        \n",
    "        # Resize for segmentation\n",
    "        img_for_segmentation = cv2.resize(img, (segmentation_shape[1], segmentation_shape[0]))\n",
    "        \n",
    "        # Enhance contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        img_for_segmentation = clahe.apply(img_for_segmentation)\n",
    "        \n",
    "        # Prepare for segmentation model\n",
    "        img_for_segmentation = np.expand_dims(np.expand_dims(img_for_segmentation, axis=-1), axis=0) / 255.0\n",
    "        \n",
    "        # Get segmentation mask\n",
    "        segmentation_output = finger_segmentation_model.predict(img_for_segmentation, verbose=0)\n",
    "        \n",
    "        # Process mask\n",
    "        if isinstance(segmentation_output, list) and len(segmentation_output) > 0:\n",
    "            mask = segmentation_output[0]\n",
    "        else:\n",
    "            mask = np.ones(img.shape, dtype=np.uint8)\n",
    "        \n",
    "        mask = (mask > 0.5).astype(np.uint8)\n",
    "        \n",
    "        # Convert 3D mask to 2D if needed\n",
    "        if len(mask.shape) == 3:\n",
    "            mask_2d = mask[:, :, 0]\n",
    "        else:\n",
    "            mask_2d = mask\n",
    "        \n",
    "        # Resize mask and apply to image\n",
    "        mask_resized = cv2.resize(mask_2d, (img.shape[1], img.shape[0]))\n",
    "        img = img * mask_resized\n",
    "        \n",
    "        # Resize for recognition model\n",
    "        img = cv2.resize(img, (input_shape[1], input_shape[0]))\n",
    "        \n",
    "        # Normalize and add channel dimension\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        return img\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocess_fingerprint: {e}\")\n",
    "        raise\n",
    "\n",
    "# Function to create embedding extractor model\n",
    "def create_embedding_model(recognition_model):\n",
    "    feature_extractor = recognition_model.get_layer('functional')\n",
    "    input_shape = feature_extractor.input_shape[1:]\n",
    "    new_input = keras.layers.Input(shape=input_shape)\n",
    "    embedding = feature_extractor(new_input)\n",
    "    embedding_model = keras.Model(inputs=new_input, outputs=embedding)\n",
    "    return embedding_model\n",
    "\n",
    "# Get embedding extractor\n",
    "embedding_model = create_embedding_model(fingerprint_recognition_model)\n",
    "\n",
    "# Function to process new employee fingerprints\n",
    "def process_new_employee(employee_id, fingerprint_images_paths):\n",
    "    print(f\"Processing fingerprints for employee {employee_id}\")\n",
    "    \n",
    "    processed_dir = f\"../processed_fingerprints/employee_{employee_id}\"\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    \n",
    "    fingerprints = []\n",
    "    \n",
    "    for i, img_path in enumerate(fingerprint_images_paths):\n",
    "        try:\n",
    "            processed_img = preprocess_fingerprint(img_path)\n",
    "            processed_path = os.path.join(processed_dir, f\"fp_{i}.npy\")\n",
    "            np.save(processed_path, processed_img)\n",
    "            fingerprints.append(processed_img)\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {img_path}: {e}\")\n",
    "    \n",
    "    if len(fingerprints) == 0:\n",
    "        raise ValueError(f\"No fingerprints were successfully processed for employee {employee_id}\")\n",
    "        \n",
    "    return np.array(fingerprints)\n",
    "\n",
    "# Function to enroll employees\n",
    "def enroll_employees(employee_data_paths):\n",
    "    new_employees_data = {}\n",
    "    \n",
    "    for employee_id, image_paths in employee_data_paths.items():\n",
    "        try:\n",
    "            fingerprints = process_new_employee(employee_id, image_paths)\n",
    "            new_employees_data[employee_id] = fingerprints\n",
    "            print(f\"Successfully enrolled employee {employee_id} with {len(fingerprints)} fingerprints\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to enroll employee {employee_id}: {e}\")\n",
    "    \n",
    "    if not new_employees_data:\n",
    "        raise ValueError(\"No employees were successfully enrolled\")\n",
    "    \n",
    "    # Create embeddings database\n",
    "    embeddings_db = {}\n",
    "    for employee_id, fingerprints in new_employees_data.items():\n",
    "        employee_embeddings = embedding_model.predict(fingerprints, verbose=0)\n",
    "        embeddings_db[employee_id] = np.mean(employee_embeddings, axis=0)  # Store average embedding\n",
    "    \n",
    "    # Save embeddings database\n",
    "    os.makedirs(\"../fingerprint_adapting_models\", exist_ok=True)\n",
    "    np.save(\"../fingerprint_adapting_models/employee_embeddings.npy\", embeddings_db)\n",
    "    \n",
    "    return embeddings_db\n",
    "\n",
    "# Function to recognize employees from new fingerprint\n",
    "def recognize_employee(image_path, embeddings_db=None, threshold=0.7):\n",
    "    try:\n",
    "        # Preprocess image\n",
    "        processed_img = preprocess_fingerprint(image_path)\n",
    "        processed_img = np.expand_dims(processed_img, axis=0)\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        # Similarity matching using embeddings\n",
    "        if embeddings_db is not None:\n",
    "            # Get embedding for the input fingerprint\n",
    "            embedding = embedding_model.predict(processed_img, verbose=0)[0]\n",
    "            \n",
    "            # Find most similar embedding\n",
    "            best_match = None\n",
    "            best_similarity = -1\n",
    "            \n",
    "            for employee_id, stored_embedding in embeddings_db.items():\n",
    "                # Compute cosine similarity\n",
    "                similarity = np.dot(embedding, stored_embedding) / (np.linalg.norm(embedding) * np.linalg.norm(stored_embedding))\n",
    "                \n",
    "                if similarity > best_similarity:\n",
    "                    best_similarity = similarity\n",
    "                    best_match = employee_id\n",
    "            \n",
    "            if best_similarity >= threshold:\n",
    "                results[\"similarity\"] = {\"employee_id\": best_match, \"confidence\": float(best_similarity)}\n",
    "            else:\n",
    "                results[\"similarity\"] = {\"employee_id\": None, \"confidence\": float(best_similarity)}\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during recognition: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "def generate_employee_data(dir):\n",
    "    employee_data = {}\n",
    "    for _employee_id in os.listdir(dir):\n",
    "        employee_data[_employee_id] = []\n",
    "        for _employee_fingerprint in os.listdir(f\"{dir}/{_employee_id}\"):\n",
    "            employee_data[_employee_id].append(f\"{dir}/{_employee_id}/{_employee_fingerprint}\")\n",
    "    return employee_data\n",
    "\n",
    "# Check if models are loaded successfully\n",
    "if 'fingerprint_recognition_model' not in globals() or 'finger_segmentation_model' not in globals():\n",
    "    print(\"Models failed to load. Please check model paths and formats.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Ensure data paths are correct\n",
    "EMPLOYEE_DIR = \"../fingerprint_adapting_dataset\"\n",
    "employee_data_paths = generate_employee_data(dir=EMPLOYEE_DIR)\n",
    "\n",
    "try:\n",
    "    # Enroll employees\n",
    "    embeddings_db = enroll_employees(employee_data_paths)\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing recognition with image: ../fingerprint_adapting_dataset/102/102_2.bmp\n",
      "Expected ID: 102\n",
      "Recognized ID: 102\n",
      "Confidence: 0.97\n",
      "{'similarity': {'employee_id': '102', 'confidence': 0.9681127071380615}}\n",
      "✅ MATCH SUCCESSFUL!\n"
     ]
    }
   ],
   "source": [
    "# Test recognition with random employee\n",
    "random_employee_id = random.randint(102, 109)\n",
    "random_employee_fingerprint_position = random.randint(1, 5)\n",
    "test_image = f\"{EMPLOYEE_DIR}/{random_employee_id}/{random_employee_id}_{random_employee_fingerprint_position}.bmp\"\n",
    "if os.path.exists(test_image):\n",
    "    print(f\"Testing recognition with image: {test_image}\")\n",
    "    result = recognize_employee(\n",
    "        test_image, \n",
    "        embeddings_db=embeddings_db\n",
    "    )\n",
    "    \n",
    "    # Compare expected vs actual results\n",
    "    expected_id = str(random_employee_id)\n",
    "    actual_id = result.get('similarity', {}).get('employee_id')\n",
    "    confidence = result.get('similarity', {}).get('confidence', 0)\n",
    "    \n",
    "    print(f\"Expected ID: {expected_id}\")\n",
    "    print(f\"Recognized ID: {actual_id}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "    print(f\"{result}\")\n",
    "    if expected_id == actual_id:\n",
    "        print(\"✅ MATCH SUCCESSFUL!\")\n",
    "    else:\n",
    "        print(\"❌ MATCH FAILED!\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Test image {test_image} not found!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recognition Accuracy: 76.62% (59/77 successful matches)\n"
     ]
    }
   ],
   "source": [
    "def test_recognition_accuracy(employee_data_paths, embeddings_db, threshold=0.7):\n",
    "    total_tests = 0\n",
    "    successful_matches = 0\n",
    "\n",
    "    for employee_id, image_paths in employee_data_paths.items():\n",
    "        # if employee_id == 101 or employee_id == '101': continue\n",
    "        # print(employee_id)\n",
    "        for img_path in image_paths:\n",
    "            if os.path.exists(img_path):\n",
    "                result = recognize_employee(img_path, embeddings_db=embeddings_db, threshold=threshold)\n",
    "                \n",
    "                expected_id = str(employee_id)\n",
    "                actual_id = result.get('similarity', {}).get('employee_id')\n",
    "                confidence = result.get('similarity', {}).get('confidence', 0)\n",
    "\n",
    "                # print(f\"\\nTesting Image: {img_path}\")\n",
    "                # print(f\"Expected ID: {expected_id}\")\n",
    "                # print(f\"Recognized ID: {actual_id}\")\n",
    "                # print(f\"Confidence: {confidence:.2f}\")\n",
    "\n",
    "                if expected_id == actual_id:\n",
    "                    # print(\"✅ MATCH SUCCESSFUL!\")\n",
    "                    successful_matches += 1\n",
    "                # else:\n",
    "                #     print(\"❌ MATCH FAILED!\")\n",
    "\n",
    "                total_tests += 1\n",
    "\n",
    "    # Calculate accuracy\n",
    "    if total_tests > 0:\n",
    "        accuracy = (successful_matches / total_tests) * 100\n",
    "        print(f\"\\nRecognition Accuracy: {accuracy:.2f}% ({successful_matches}/{total_tests} successful matches)\")\n",
    "    else:\n",
    "        print(\"No test cases found!\")\n",
    "\n",
    "# Run accuracy test\n",
    "test_recognition_accuracy(employee_data_paths, embeddings_db)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
